{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9606935,"sourceType":"datasetVersion","datasetId":5861572},{"sourceId":9606911,"sourceType":"datasetVersion","datasetId":5861555}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"text-align: center;\"><strong>Custom Encoder Decoder Model</strong> :</h1>\n\n## We'll learn how to create a VisionEncoderDecoderModel using any Vision model as Encoder and any LLM as Decoder.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(60, 121, 245) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 1. Importing Some Libraries / Dependencies </b></div>","metadata":{}},{"cell_type":"code","source":"!pip install jiwer","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-14T14:32:29.402246Z","iopub.execute_input":"2024-10-14T14:32:29.402663Z","iopub.status.idle":"2024-10-14T14:32:41.055993Z","shell.execute_reply.started":"2024-10-14T14:32:29.402625Z","shell.execute_reply":"2024-10-14T14:32:41.054799Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: jiwer in /opt/conda/lib/python3.10/site-packages (3.0.4)\nRequirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (8.1.7)\nRequirement already satisfied: rapidfuzz<4,>=3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (3.10.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from dataclasses import dataclass\nimport warnings\nimport torch\nfrom datasets import Dataset, DatasetDict\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport os\nfrom jiwer import wer , cer\nfrom transformers import (\n    VisionEncoderDecoderModel,\n    AutoModelForSeq2SeqLM,\n    Seq2SeqTrainer,\n    Seq2SeqTrainingArguments,\n    ViTImageProcessor,\n    AutoTokenizer,\n    default_data_collator\n)\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-10-14T14:30:03.113519Z","iopub.execute_input":"2024-10-14T14:30:03.114493Z","iopub.status.idle":"2024-10-14T14:30:03.120998Z","shell.execute_reply.started":"2024-10-14T14:30:03.114450Z","shell.execute_reply":"2024-10-14T14:30:03.119939Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(255, 217, 19) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 2. ⚙️ The \"Too Cool for School\" Config</b></div>","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass Config:\n    output_dir: str = \"/kaggle/working/\"\n    encoder_checkpoint : str = \"google/vit-base-patch16-224-in21k\"  \n    decoder_checkpoint : str = \"gpt2\"\n    max_length: int = 512  \n    early_stoping : str = 'never'\n    no_n_gram : int = 3\n    length_penalty : int = 2.0\n    num_beams : int = 4\n    per_device_train_batch_size: int = 2 \n    per_device_eval_batch_size: int = 12\n    saving_steps : int = 25\n    logging_steps : int = 25\n    eval_steps : int = 25\n    lr: float = 2e-5\n    report : str = 'none'\n    startegy : str = 'steps'\n    epoch : int = 1\n    \ncf = Config()\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-14T14:30:06.588973Z","iopub.execute_input":"2024-10-14T14:30:06.589907Z","iopub.status.idle":"2024-10-14T14:30:06.598502Z","shell.execute_reply.started":"2024-10-14T14:30:06.589864Z","shell.execute_reply":"2024-10-14T14:30:06.597401Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(255, 7, 19) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 3. Initializing the Custom Encoder Decoder Model </b></div>","metadata":{}},{"cell_type":"code","source":"model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\n    cf.encoder_checkpoint, cf.decoder_checkpoint ,trust_remote_code=True\n)\n\nfeature_extractor = ViTImageProcessor.from_pretrained(cf.encoder_checkpoint)\ntokenizer = AutoTokenizer.from_pretrained(cf.decoder_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:39:01.307167Z","iopub.execute_input":"2024-10-14T13:39:01.308092Z","iopub.status.idle":"2024-10-14T13:39:02.573976Z","shell.execute_reply.started":"2024-10-14T13:39:01.308052Z","shell.execute_reply":"2024-10-14T13:39:02.573156Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <div style=\"font-size:32px; font-family:consolas; text-align:center; color:rgb(255, 0, 0);\">\n# <b> Set special <span style=\"color:rgb(0, 255, 0);\">Tokens</span> for the <span style=\"color:rgb(0, 0, 255);\">Encoder Decoder Model</span> </b>\n### > eos\n### > bos\n### > pad","metadata":{}},{"cell_type":"code","source":"model.config.decoder_start_token_id = tokenizer.bos_token_id\ntokenizer.pad_token = tokenizer.eos_token  \nmodel.config.pad_token_id = tokenizer.pad_token_id","metadata":{"execution":{"iopub.status.busy":"2024-10-14T14:30:15.136148Z","iopub.execute_input":"2024-10-14T14:30:15.136814Z","iopub.status.idle":"2024-10-14T14:30:15.141352Z","shell.execute_reply.started":"2024-10-14T14:30:15.136775Z","shell.execute_reply":"2024-10-14T14:30:15.140424Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"font-size:32px; font-family:consolas; text-align:center; color:rgb(255, 70, 80);\">\n# <b> Make sure <span style=\"color:rgb(255, 30, 20);\">vocab size</span> is set <span style=\"color:rgb(3, 3, 255);\">correctly</span> </b>","metadata":{}},{"cell_type":"code","source":"model.config.vocab_size = model.config.decoder.vocab_size","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:38:02.808726Z","iopub.execute_input":"2024-10-14T13:38:02.809028Z","iopub.status.idle":"2024-10-14T13:38:02.818469Z","shell.execute_reply.started":"2024-10-14T13:38:02.808990Z","shell.execute_reply":"2024-10-14T13:38:02.817653Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"font-size:32px; font-family:consolas; text-align:center; color:rgb(255, 70, 80);\">\n# <b> Set <span style=\"color:rgb(255, 30, 20);\">Beam Search </span> parameters <span style=\"color:rgb(3, 3, 255);\"></span> </b>","metadata":{}},{"cell_type":"code","source":"model.config.eos_token_id = tokenizer.sep_token_id\nmodel.config.max_length = cf.max_length\nmodel.config.early_stopping = cf.early_stoping\nmodel.config.no_repeat_ngram_size = cf.no_n_gram\nmodel.config.length_penalty = cf.length_penalty\nmodel.config.num_beams = cf.num_beams\nmodel.decoder.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:38:02.819448Z","iopub.execute_input":"2024-10-14T13:38:02.819769Z","iopub.status.idle":"2024-10-14T13:38:02.838643Z","shell.execute_reply.started":"2024-10-14T13:38:02.819739Z","shell.execute_reply":"2024-10-14T13:38:02.837683Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Embedding(50257, 768)"},"metadata":{}}]},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(255, 0, 19) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 4.MODEL ARCHITECTURE</b></div>","metadata":{}},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:38:02.839959Z","iopub.execute_input":"2024-10-14T13:38:02.840577Z","iopub.status.idle":"2024-10-14T13:38:02.852516Z","shell.execute_reply.started":"2024-10-14T13:38:02.840530Z","shell.execute_reply":"2024-10-14T13:38:02.851546Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"VisionEncoderDecoderModel(\n  (encoder): ViTModel(\n    (embeddings): ViTEmbeddings(\n      (patch_embeddings): ViTPatchEmbeddings(\n        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n      )\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): ViTEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x ViTLayer(\n          (attention): ViTSdpaAttention(\n            (attention): ViTSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (pooler): ViTPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (decoder): GPT2LMHeadModel(\n    (transformer): GPT2Model(\n      (wte): Embedding(50257, 768)\n      (wpe): Embedding(1024, 768)\n      (drop): Dropout(p=0.1, inplace=False)\n      (h): ModuleList(\n        (0-11): 12 x GPT2Block(\n          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (attn): GPT2SdpaAttention(\n            (c_attn): Conv1D(nf=2304, nx=768)\n            (c_proj): Conv1D(nf=768, nx=768)\n            (attn_dropout): Dropout(p=0.1, inplace=False)\n            (resid_dropout): Dropout(p=0.1, inplace=False)\n          )\n          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (crossattention): GPT2SdpaAttention(\n            (c_attn): Conv1D(nf=1536, nx=768)\n            (q_attn): Conv1D(nf=768, nx=768)\n            (c_proj): Conv1D(nf=768, nx=768)\n            (attn_dropout): Dropout(p=0.1, inplace=False)\n            (resid_dropout): Dropout(p=0.1, inplace=False)\n          )\n          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): GPT2MLP(\n            (c_fc): Conv1D(nf=3072, nx=768)\n            (c_proj): Conv1D(nf=768, nx=3072)\n            (act): NewGELUActivation()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"![02szHZu.png](https://imgur.com/02szHZu.png)","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"font-size:32px; font-family:consolas; text-align:center; color:rgb(255, 70, 80);\">\n# <b>Verify <span style=\"color:rgb(255, 30, 20);\"></span><span style=\"color:rgb(3, 3, 255);\">Configurtions</span> </b>","metadata":{}},{"cell_type":"code","source":"print(f\"Decoder Start Token ID: {model.config.decoder_start_token_id}\")\nprint(f\"Pad Token ID: {model.config.pad_token_id}\")\nprint(f\"Vocabulary Size: {model.config.vocab_size}\")\n\n#Very Important Step otherwise you'll see errors during training { adjust this as your choice}","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:38:02.853932Z","iopub.execute_input":"2024-10-14T13:38:02.854240Z","iopub.status.idle":"2024-10-14T13:38:02.862400Z","shell.execute_reply.started":"2024-10-14T13:38:02.854209Z","shell.execute_reply":"2024-10-14T13:38:02.861441Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Decoder Start Token ID: 50256\nPad Token ID: 50256\nVocabulary Size: 50257\n","output_type":"stream"}]},{"cell_type":"code","source":"max_target_length = cf.max_length","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:38:02.866722Z","iopub.execute_input":"2024-10-14T13:38:02.867066Z","iopub.status.idle":"2024-10-14T13:38:02.871307Z","shell.execute_reply.started":"2024-10-14T13:38:02.867034Z","shell.execute_reply":"2024-10-14T13:38:02.870283Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(31, 193, 27) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 5. Loading Files </b></div>","metadata":{}},{"cell_type":"code","source":"csv_file = \"/kaggle/input/ai-god/train.csv\"\ndf = pd.read_csv(csv_file)\n\ndf = df.head(5000)  #------> only using first 5k data , you can use as much as you can ^_^","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:38:02.872475Z","iopub.execute_input":"2024-10-14T13:38:02.873325Z","iopub.status.idle":"2024-10-14T13:38:02.936581Z","shell.execute_reply.started":"2024-10-14T13:38:02.873279Z","shell.execute_reply":"2024-10-14T13:38:02.935564Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"image_folder = \"/kaggle/input/ai-god-2/train_images/train_images\"","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:38:02.937949Z","iopub.execute_input":"2024-10-14T13:38:02.938388Z","iopub.status.idle":"2024-10-14T13:38:02.943005Z","shell.execute_reply.started":"2024-10-14T13:38:02.938336Z","shell.execute_reply":"2024-10-14T13:38:02.941885Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(82, 15, 70) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 6. A Function to load images using the ID </b></div>","metadata":{}},{"cell_type":"code","source":"def load_images(image_id):\n    image_path = os.path.join(image_folder, f\"{image_id}.png\")  #----> Adjust the file extension if needed\n    image = Image.open(image_path).convert(\"RGB\")\n    return feature_extractor(images=image, return_tensors=\"pt\").pixel_values.squeeze(0)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:38:02.944226Z","iopub.execute_input":"2024-10-14T13:38:02.944607Z","iopub.status.idle":"2024-10-14T13:38:02.952995Z","shell.execute_reply.started":"2024-10-14T13:38:02.944575Z","shell.execute_reply":"2024-10-14T13:38:02.952050Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"font-size:32px; font-family:consolas; text-align:center; color:rgb(255, 70, 80);\">\n# <b>Converting the <span style=\"color:rgb(255, 30, 20);\"></span> DataFrame into a <span style=\"color:rgb(3, 3, 255);\">Dataset</span> </b>","metadata":{}},{"cell_type":"code","source":"dataset = Dataset.from_pandas(df)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T14:30:28.502555Z","iopub.execute_input":"2024-10-14T14:30:28.503458Z","iopub.status.idle":"2024-10-14T14:30:28.519993Z","shell.execute_reply.started":"2024-10-14T14:30:28.503419Z","shell.execute_reply":"2024-10-14T14:30:28.518983Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(82, 15, 70) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 7. A Function to load images and add them to the dataset</b></div>","metadata":{}},{"cell_type":"code","source":"def add_image(example):\n    example['pixel_values'] = load_images(example['unique Id'])\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:38:02.975719Z","iopub.execute_input":"2024-10-14T13:38:02.976465Z","iopub.status.idle":"2024-10-14T13:38:02.980992Z","shell.execute_reply.started":"2024-10-14T13:38:02.976421Z","shell.execute_reply":"2024-10-14T13:38:02.979870Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(add_image)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T14:30:32.868114Z","iopub.execute_input":"2024-10-14T14:30:32.868992Z","iopub.status.idle":"2024-10-14T14:31:38.103680Z","shell.execute_reply.started":"2024-10-14T14:30:32.868951Z","shell.execute_reply":"2024-10-14T14:31:38.102718Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b6addfd376942a39d4eb25c7e535455"}},"metadata":{}}]},{"cell_type":"markdown","source":"# <div style=\"font-size:32px; font-family:consolas; text-align:center; color:rgb(255, 70, 80);\">\n# <b>Tokenizing the <span style=\"color:rgb(255, 30, 20);\">Labels </span> and add them to the <span style=\"color:rgb(3, 3, 255);\">Dataset</span> </b>","metadata":{}},{"cell_type":"code","source":"def tokenize_labels(example):\n    example['labels'] = tokenizer(example['transcription'],\n                                  return_tensors='pt',\n                                  truncation=True,\n                                  padding=\"max_length\", \n                                  max_length=max_target_length).input_ids.squeeze(0)\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:41:33.067414Z","iopub.execute_input":"2024-10-14T13:41:33.068378Z","iopub.status.idle":"2024-10-14T13:41:33.073618Z","shell.execute_reply.started":"2024-10-14T13:41:33.068332Z","shell.execute_reply":"2024-10-14T13:41:33.072630Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(tokenize_labels)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T14:31:55.125829Z","iopub.execute_input":"2024-10-14T14:31:55.126601Z","iopub.status.idle":"2024-10-14T14:32:06.091972Z","shell.execute_reply.started":"2024-10-14T14:31:55.126558Z","shell.execute_reply":"2024-10-14T14:32:06.090874Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb72e13e93214487859e2aac356035a4"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = dataset.remove_columns([\"unique Id\", \"transcription\"]) #------> Removing the unnecessary columns","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:44:06.346395Z","iopub.execute_input":"2024-10-14T13:44:06.347637Z","iopub.status.idle":"2024-10-14T13:44:06.354722Z","shell.execute_reply.started":"2024-10-14T13:44:06.347580Z","shell.execute_reply":"2024-10-14T13:44:06.353675Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"font-size:32px; font-family:consolas; text-align:center; color:rgb(255, 70, 80);\">\n# <b>Spliting the <span style=\"color:rgb(255, 30, 20);\">Dataset </span> into the <span style=\"color:rgb(3, 3, 255);\">train , test , valid sets</span> </b>","metadata":{}},{"cell_type":"code","source":"train_testvalid = dataset.train_test_split(0.1)\ntest_valid = train_testvalid['test'].train_test_split(0.5)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:44:11.213625Z","iopub.execute_input":"2024-10-14T13:44:11.214602Z","iopub.status.idle":"2024-10-14T13:44:11.240074Z","shell.execute_reply.started":"2024-10-14T13:44:11.214544Z","shell.execute_reply":"2024-10-14T13:44:11.239149Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_test_valid_dataset = DatasetDict({\n    'train': train_testvalid['train'],\n    'test': test_valid['test'],\n    'valid': test_valid['train']\n})\n\nprint(train_test_valid_dataset)  ","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:44:13.187582Z","iopub.execute_input":"2024-10-14T13:44:13.188481Z","iopub.status.idle":"2024-10-14T13:44:13.193975Z","shell.execute_reply.started":"2024-10-14T13:44:13.188437Z","shell.execute_reply":"2024-10-14T13:44:13.192936Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['pixel_values', 'labels'],\n        num_rows: 4500\n    })\n    test: Dataset({\n        features: ['pixel_values', 'labels'],\n        num_rows: 250\n    })\n    valid: Dataset({\n        features: ['pixel_values', 'labels'],\n        num_rows: 250\n    })\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a id=\"8\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(200, 13, 12) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 8. Custom compute metrices ( WER , CER )</b></div>","metadata":{}},{"cell_type":"code","source":"def custom_compute_metrics(pred):\n    preds = pred.predictions\n    labels = pred.label_ids\n\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    wer_score = wer(decoded_labels, decoded_preds)  #---->WER\n\n    cer_score = cer(decoded_labels, decoded_preds)  #---->CER\n\n    return {\n        'wer': wer_score,\n        'cer': cer_score,\n    }","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:44:18.256786Z","iopub.execute_input":"2024-10-14T13:44:18.257238Z","iopub.status.idle":"2024-10-14T13:44:18.263702Z","shell.execute_reply.started":"2024-10-14T13:44:18.257199Z","shell.execute_reply":"2024-10-14T13:44:18.262749Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"for param in model.encoder.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:44:22.353945Z","iopub.execute_input":"2024-10-14T13:44:22.354370Z","iopub.status.idle":"2024-10-14T13:44:22.360230Z","shell.execute_reply.started":"2024-10-14T13:44:22.354317Z","shell.execute_reply":"2024-10-14T13:44:22.359261Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"9\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(20, 13, 121) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 9. Training Arguments / Trainer </b></div>","metadata":{}},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    predict_with_generate=True,\n    eval_strategy= cf.startegy,\n    per_device_train_batch_size=cf.per_device_train_batch_size,\n    per_device_eval_batch_size=cf.per_device_eval_batch_size,\n    overwrite_output_dir=True,\n    fp16= True,\n    load_best_model_at_end=True,\n    output_dir=cf.output_dir,\n    logging_steps=cf.logging_steps,\n    save_steps=cf.saving_steps,\n    eval_steps=cf.eval_steps,\n    report_to =cf.report,\n    learning_rate = cf.lr,\n    num_train_epochs = cf.epoch\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:44:27.202444Z","iopub.execute_input":"2024-10-14T13:44:27.203252Z","iopub.status.idle":"2024-10-14T13:44:27.304985Z","shell.execute_reply.started":"2024-10-14T13:44:27.203205Z","shell.execute_reply":"2024-10-14T13:44:27.304111Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n        model=model,\n        tokenizer=tokenizer,\n        args=training_args,\n        train_dataset=train_test_valid_dataset['train'],\n        eval_dataset=train_test_valid_dataset['valid'],\n        data_collator=default_data_collator,\n        compute_metrics=custom_compute_metrics,\n        )","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:44:30.511358Z","iopub.execute_input":"2024-10-14T13:44:30.512281Z","iopub.status.idle":"2024-10-14T13:44:31.003305Z","shell.execute_reply.started":"2024-10-14T13:44:30.512236Z","shell.execute_reply":"2024-10-14T13:44:31.002468Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:44:34.977190Z","iopub.execute_input":"2024-10-14T13:44:34.977590Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='176' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 176/2250 07:02 < 1:23:51, 0.41 it/s, Epoch 0.08/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer</th>\n      <th>Cer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>4.768900</td>\n      <td>0.247760</td>\n      <td>1.032375</td>\n      <td>1.030173</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.239500</td>\n      <td>0.227945</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.231900</td>\n      <td>0.220672</td>\n      <td>1.032012</td>\n      <td>1.025669</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.223000</td>\n      <td>0.214311</td>\n      <td>1.046199</td>\n      <td>0.754969</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.213900</td>\n      <td>0.210121</td>\n      <td>1.644234</td>\n      <td>0.822251</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.222900</td>\n      <td>0.206539</td>\n      <td>1.289560</td>\n      <td>0.739311</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a id=\"BONUS\"></a>\n# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(20, 13, 121) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> BONUS : INFERENCE</b></div>","metadata":{}},{"cell_type":"code","source":"from transformers import VisionEncoderDecoderModel, AutoTokenizer ,ViTImageProcessor","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:38:49.640104Z","iopub.status.idle":"2024-10-14T13:38:49.640448Z","shell.execute_reply.started":"2024-10-14T13:38:49.640271Z","shell.execute_reply":"2024-10-14T13:38:49.640288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = VisionEncoderDecoderModel.from_pretrained(saved_model_checkpoint)\n\nfeature_extractor = ViTImageProcessor.from_pretrained(saved_model_checkpoint)\ntokenizer = AutoTokenizer.from_pretrained(saved_model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:38:49.642214Z","iopub.status.idle":"2024-10-14T13:38:49.642585Z","shell.execute_reply.started":"2024-10-14T13:38:49.642403Z","shell.execute_reply":"2024-10-14T13:38:49.642422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:38:49.643507Z","iopub.status.idle":"2024-10-14T13:38:49.643892Z","shell.execute_reply.started":"2024-10-14T13:38:49.643683Z","shell.execute_reply":"2024-10-14T13:38:49.643702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-14T13:38:49.645341Z","iopub.status.idle":"2024-10-14T13:38:49.645866Z","shell.execute_reply.started":"2024-10-14T13:38:49.645572Z","shell.execute_reply":"2024-10-14T13:38:49.645598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"box-shadow: rgba(240, 46, 170, 0.4) -5px 5px inset, rgba(240, 46, 170, 0.3) -10px 10px inset, rgba(240, 46, 17, 0.2) -15px 15px inset, rgba(24, 46, 170, 0.1) -20px 20px inset, rgba(240, 46, 170, 0.05) -25px 25px inset; padding:20px; font-size:30px; font-family: consolas; display:fill; border-radius:15px; color: rgba(240, 0, 170, 0.7)\"> <b> 💻 Thank You!</b></div>\n\n<p style=\"font-family:verdana; color:rgb(34, 34, 34); font-family: consolas; font-size: 16px;\"> If you enjoy this Custom Vision Encoder Decoder Model,upvote this notebook. Happy coding!🚀💻🌟. <br>\n    </p>","metadata":{}},{"cell_type":"markdown","source":"![6np2LHr.gif](https://imgur.com/6np2LHr.gif)","metadata":{}}]}